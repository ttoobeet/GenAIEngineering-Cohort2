{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536ac465",
   "metadata": {},
   "source": [
    "Google Colab: https://colab.research.google.com/drive/185op1Hy26orcDx1Lf4RXoIToBMlwzJf1?usp=sharing\n",
    "\n",
    "HuggingFace: https://huggingface.co/amazon/chronos-t5-small\n",
    "\n",
    "# Necessary Libraries\n",
    "\n",
    "This code imports all the necessary libraries for a comprehensive time series forecasting workflow:\n",
    "\n",
    "### Environment and Configuration\n",
    "- `os`: For operating system operations and environment variables\n",
    "- `json`: For handling JSON data structures\n",
    "- `datetime`: For working with dates and times\n",
    "- `dotenv`: For loading environment variables from a `.env` file\n",
    "\n",
    "### Model Management\n",
    "- `HfApi` and `hf_hub_download`: For interacting with Hugging Face's model hub\n",
    "- `pipeline`: Hugging Face's unified API for using pre-trained models\n",
    "\n",
    "### Data Science Stack\n",
    "- `matplotlib.pyplot`: For creating visualizations\n",
    "- `numpy`: For numerical computing and array operations\n",
    "- `pandas`: For data manipulation and analysis\n",
    "\n",
    "### Deep Learning and Forecasting\n",
    "- `torch`: PyTorch library for deep learning\n",
    "- `ChronosPipeline`: Amazon's Chronos library for time series forecasting\n",
    "\n",
    "The comment at the end of the Chronos import provides installation instructions for the library, which can be installed directly from GitHub using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3de16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, datetime\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from chronos import ChronosPipeline #pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7002eb",
   "metadata": {},
   "source": [
    "\n",
    "# Loading Environment Variables for Hugging Face\n",
    "\n",
    "\n",
    "This code snippet performs two essential operations:\n",
    "\n",
    "1. `load_dotenv()` - Loads environment variables from a `.env` file into the application's environment. This is a common pattern for securely storing configuration and sensitive information outside of the source code.\n",
    "\n",
    "2. `hf_key = os.getenv(\"HF_TOKEN\")` - Retrieves the Hugging Face API token from the environment variables and assigns it to the variable `hf_key`. This token is required for authenticated access to the Hugging Face Hub services, including downloading private models or models with gated access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "hf_key=os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# print(hf_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f50228",
   "metadata": {},
   "source": [
    "## Time Series Model:\n",
    "\n",
    "- **`ChronosPipeline.from_pretrained()`**: Loads a pre-trained time series forecasting model\n",
    "- **`\"amazon/chronos-t5-small\"`**: The specific model being loaded - a smaller version of Amazon's Chronos T5 model\n",
    "- **`device_map=\"cpu\"`**: Configures the model to run on CPU rather than GPU\n",
    "- **`torch_dtype=torch.bfloat16`**: Sets the tensor data type to Brain Floating Point (bfloat16)\n",
    "  - bfloat16 is a 16-bit floating-point format that maintains the same dynamic range as 32-bit float but with reduced precision\n",
    "  - This format offers a good balance between performance and accuracy for many machine learning workloads\n",
    "\n",
    "Once loaded, the pipeline can be used for time series forecasting tasks with the pre-trained weights and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\"amazon/chronos-t5-small\",device_map=\"cpu\",torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fce28f",
   "metadata": {},
   "source": [
    "# Loading Time Series Data with Pandas\n",
    "\n",
    "- The code loads the classic \"Air Passengers\" dataset, which contains monthly totals of international airline passengers from 1949 to 1960\n",
    "- `pd.read_csv()` is used to read data directly from a URL\n",
    "- The URL points to a CSV file in Aileen Nielsen's TimeSeriesAnalysisWithPython GitHub repository\n",
    "- The resulting dataframe `df` will contain columns for the month and number of passengers\n",
    "- The `print(df)` statement displays the contents of the dataframe in the console\n",
    "\n",
    "This dataset is commonly used for demonstrating time series analysis techniques as it shows clear seasonal patterns and an upward trend over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d0c14",
   "metadata": {},
   "source": [
    "# Converting Pandas Data to PyTorch Tensor\n",
    "\n",
    "- This code extracts the \"#Passengers\" column from the pandas DataFrame `df`\n",
    "- The data is converted to a PyTorch tensor using `torch.tensor()`\n",
    "- `dtype=torch.bfloat16` specifies that the tensor should use the Brain Floating Point (bfloat16) data type\n",
    "- bfloat16 is a 16-bit floating-point format that:\n",
    "  - Maintains the same exponent range as 32-bit float (good for representing large and small values)\n",
    "  - Uses fewer bits for the mantissa (reduced precision)\n",
    "  - Provides memory and computational efficiency benefits\n",
    "  - Is particularly well-suited for neural network operations\n",
    "\n",
    "The resulting `context` tensor can now be used as input to PyTorch-based models like the Chronos time series forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb652c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.tensor(df[\"#Passengers\"], dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f864d3",
   "metadata": {},
   "source": [
    "# Time Series Forecasting with Chronos\n",
    "\n",
    "- **Prediction Setup**:\n",
    "  - `prediction_length = 12` sets the forecast horizon to 12 time steps (months)\n",
    "  - `pipeline.predict()` generates forecast samples for the specified prediction length\n",
    "\n",
    "- **Forecast Processing**:\n",
    "  - `forecast_index` creates a range for plotting the forecast period\n",
    "  - `np.quantile()` calculates the probabilistic forecast intervals:\n",
    "    - 10th percentile (low bound)\n",
    "    - 50th percentile (median forecast)\n",
    "    - 90th percentile (high bound)\n",
    "  - `.cpu().detach().tolist()` converts the PyTorch tensor to a NumPy array for quantile calculation\n",
    "\n",
    "- **Visualization**:\n",
    "  - Historical data is plotted in blue\n",
    "  - Median forecast is plotted as a red line\n",
    "  - The 80% prediction interval (between 10th and 90th percentiles) is shown as a shaded area\n",
    "  - The result shows both the historical passenger data and the probabilistic forecast for the next year\n",
    "\n",
    "This code demonstrates a complete forecasting workflow from loading data to generating and visualizing probabilistic predictions using the Chronos model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "\n",
    "prediction_length = 12\n",
    "forecast = pipeline.predict(context[:-prediction_length], prediction_length)  # shape [num_series, num_samples, prediction_length]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# visualize the forecast\n",
    "forecast_index = range(len(df) - prediction_length, len(df))\n",
    "low, median, high = np.quantile(np.array(forecast[0].cpu().detach().tolist()), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7794eb",
   "metadata": {},
   "source": [
    "# Forecast Accuracy Evaluation Code Explanation\n",
    "\n",
    "This code compares forecasted values against actual values to calculate common accuracy metrics for time series forecasting. Here's a breakdown of what the code does:\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "- **forecasts**: Takes the median predictions from the model and rounds each value to 2 decimal places using a list comprehension\n",
    "- **actuals**: Extracts the last `prediction_length` values from the context tensor (the actual values we're trying to predict), converts them from PyTorch tensor to NumPy array\n",
    "\n",
    "## Accuracy Metrics Calculation\n",
    "\n",
    "\n",
    "The code calculates four standard forecasting accuracy metrics:\n",
    "\n",
    "1. **MAE (Mean Absolute Error)**: The average absolute difference between predicted and actual values\n",
    "   - Lower is better\n",
    "   - Directly interpretable in the original data units\n",
    "\n",
    "2. **RMSE (Root Mean Square Error)**: Square root of the average squared differences\n",
    "   - Gives higher weight to larger errors\n",
    "   - Also in the original data units\n",
    "\n",
    "3. **MAPE (Mean Absolute Percentage Error)**: Average percentage difference between predicted and actual values\n",
    "   - Scale-independent metric (expressed as %)\n",
    "   - Allows comparison across different datasets\n",
    "\n",
    "4. **Coverage**: The percentage of actual values that fall within the model's prediction interval (between low and high quantiles)\n",
    "   - Ideally should match the expected interval width (e.g., 80% for 10th-90th percentile interval)\n",
    "   - Measures the calibration of the uncertainty estimates\n",
    "\n",
    "## Sample Output\n",
    "\n",
    "When this code runs, it might produce output like:\n",
    "\n",
    "\n",
    "## Interpretation of Results\n",
    "\n",
    "- The **MAE** of 62.51 means that, on average, our forecasts are off by about 63 passenger units\n",
    "- The **RMSE** of 87.14 is higher than MAE, indicating some larger errors are present\n",
    "- The **MAPE** of 12.89% shows that our predictions have an average percentage error of about 13%\n",
    "- The **Coverage** of 75.00% means that 75% of actual values fell within our 80% prediction interval, slightly below the expected 80%, suggesting our prediction intervals might be slightly too narrow\n",
    "\n",
    "This evaluation helps assess both the accuracy of the point forecasts (median predictions) and the quality of the uncertainty estimates (prediction intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f04b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts=np.array([round(i,2)  for i in median])\n",
    "actuals=np.array(context[-prediction_length:].cpu().detach().tolist())\n",
    "print(\"Forecasts:\",forecasts)\n",
    "print(\"Actuals:\",actuals)\n",
    "\n",
    "mae = round(np.mean(np.abs(actuals - forecasts)), 2)\n",
    "rmse = round(np.sqrt(np.mean((actuals - forecasts)**2)), 2)\n",
    "mape = round(np.mean(np.abs((actuals - forecasts) / actuals)) * 100, 2)\n",
    "coverage = round(np.mean((actuals >= low) & (actuals <= high)) * 100, 2)\n",
    "print()\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAPE: {mape}\")\n",
    "print(f\"Coverage: {coverage}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
