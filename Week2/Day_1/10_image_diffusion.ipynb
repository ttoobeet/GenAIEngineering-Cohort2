{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679b7ec5",
   "metadata": {},
   "source": [
    "\n",
    "Google Colab:\n",
    "https://colab.research.google.com/drive/1BLRExwFvjaNIOjNg-TZrMYq9O8CVC_1y?authuser=1#scrollTo=63e98171\n",
    "\n",
    "HuggingFace: https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
    "\n",
    "## Benefits\n",
    "- Free GPU/TPU access\n",
    "- Pre-installed ML libraries\n",
    "- Google Drive integration\n",
    "- Real-time collaboration\n",
    "\n",
    "## Quick Start\n",
    "1. Open the link\n",
    "2. Make a copy (File → Save in Drive)\n",
    "3. Enable GPU (Runtime → Change runtime type)\n",
    "4. Run cells (Shift+Enter)\n",
    "\n",
    "## Tips\n",
    "- Monitor resources (Runtime → Manage sessions)\n",
    "- Save regularly (auto-disconnects after inactivity)\n",
    "- Mount Drive for persistent storage\n",
    "- Load large datasets progressively\n",
    "\n",
    "## Limitations\n",
    "- ~12 hour sessions (free tier)\n",
    "- Variable GPU availability\n",
    "- Requires stable internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e98171",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install diffusers transformers accelerate ftfy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3979f",
   "metadata": {},
   "source": [
    "# Setting Up Stable Diffusion for Image-to-Image Translation\n",
    "\n",
    "This code imports the necessary libraries for using Stable Diffusion's image-to-image translation capabilities:\n",
    "\n",
    "### Core Components:\n",
    "\n",
    "1. **PyTorch**: Deep learning framework that powers the Stable Diffusion model\n",
    "   - `torch`: Main PyTorch library for tensor operations and GPU acceleration\n",
    "\n",
    "2. **Image Processing**:\n",
    "   - `PIL.Image`: Python Imaging Library for loading and manipulating images\n",
    "   - `BytesIO`: Handles binary data as file-like objects\n",
    "   - `numpy`: Provides array operations for image data manipulation\n",
    "\n",
    "3. **Utilities**:\n",
    "   - `requests`: HTTP library for downloading images from URLs\n",
    "   - `display` from IPython: Renders images directly in Jupyter notebooks\n",
    "\n",
    "4. **Diffusion Model**:\n",
    "   - `StableDiffusionImg2ImgPipeline`: Specialized pipeline for transforming existing images based on text prompts\n",
    "\n",
    "## Functionality\n",
    "\n",
    "This setup allows you to:\n",
    "- Load source images (either locally or from URLs)\n",
    "- Provide text prompts to guide image transformation\n",
    "- Control strength of transformation through model parameters\n",
    "- Generate variations of existing images\n",
    "- Display results directly in notebook environments\n",
    "\n",
    "The image-to-image pipeline takes an initial image and modifies it according to your text prompt, preserving the overall composition while changing the style, elements, or other attributes specified in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from diffusers import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c397f",
   "metadata": {},
   "source": [
    "# Initializing Stable Diffusion for GPU Acceleration\n",
    "\n",
    "This code loads and configures the Stable Diffusion v1.4 image-to-image pipeline with GPU optimization:\n",
    "\n",
    "### Hardware Selection\n",
    "- `device = \"cuda\"`: Sets the pipeline to run on NVIDIA GPU\n",
    "  - Significantly faster than CPU for image generation\n",
    "  - Requires a CUDA-compatible NVIDIA graphics card\n",
    "\n",
    "### Model Loading Parameters\n",
    "- **Model ID**: `\"CompVis/stable-diffusion-v1-4\"`\n",
    "  - The original Stable Diffusion v1.4 release by CompVis\n",
    "  - A foundational text-to-image and image-to-image model\n",
    "\n",
    "- **Precision**: `revision=\"fp16\"` and `torch_dtype=torch.float16`\n",
    "  - Uses 16-bit floating point precision\n",
    "  - Reduces memory usage by approximately 50%\n",
    "  - Maintains good image quality while enabling faster generation\n",
    "\n",
    "- **Authentication**: `use_auth_token=True`\n",
    "  - Required to download the model\n",
    "  - Uses your Hugging Face access token\n",
    "  - Necessary because Stable Diffusion has content usage restrictions\n",
    "\n",
    "- **Device Allocation**: `.to(device)`\n",
    "  - Moves all model parameters to the GPU\n",
    "  - Prepares the pipeline for GPU-accelerated inference\n",
    "\n",
    "## Memory Requirements\n",
    "This configuration requires approximately 4-5GB of GPU VRAM, making it compatible with most modern NVIDIA GPUs including the GTX 1060 (6GB) and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e80db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091276cb",
   "metadata": {},
   "source": [
    "# Loading an Image from URL for Stable Diffusion\n",
    "\n",
    "This code fetches an image from the web and prepares it for use with the Stable Diffusion image-to-image pipeline:\n",
    "\n",
    "### Step 1: Define the Source\n",
    "- The URL points to an image hosted through DuckDuckGo's image proxy\n",
    "- The lengthy URL parameters contain the original source location and image settings\n",
    "\n",
    "### Step 2: Download the Image\n",
    "- `requests.get(url)`: Sends an HTTP GET request to retrieve the image data\n",
    "- `response.content`: Contains the binary image data in memory\n",
    "\n",
    "### Step 3: Process the Image\n",
    "- `BytesIO(response.content)`: Creates a file-like object from the binary data\n",
    "- `Image.open()`: Uses PIL to open the image from the memory buffer\n",
    "- `.convert(\"RGB\")`: Ensures the image is in RGB format\n",
    "  - Converts any grayscale, RGBA, or other formats to standard RGB\n",
    "  - Required for compatibility with Stable Diffusion\n",
    "\n",
    "### Step 4: Store for Processing\n",
    "- `init_image`: Now contains the prepared PIL Image object\n",
    "- Ready to be used as the input for the image-to-image generation process\n",
    "\n",
    "The image is now loaded in memory and properly formatted for transformation with the Stable Diffusion pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef8e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Flh6.googleusercontent.com%2Fproxy%2FQBZTSycU3BmNf_YnyU4vm7Ammqx-aKnQcXSr_mD5xn28buzYMdg4G4NZOoxF8-hhW-a_HenRvkeiOnwnRw4Ll0TYjcs9HehMcoFWWsCpqA5BKAQCOUeJ5yd2eXnIlcxd_F6n7dugodr4GuwtI7aNtIqETNci0EFPeyc6sgVUx4f_1wHb_RwEXRGTxbc3L5jqYbde-ArPVo4_HRuJPBhmq-hJ86M4%3Dw1200-h630-p-k-no-nu&f=1&nofb=1\"\n",
    "response = requests.get(url)\n",
    "init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f9077",
   "metadata": {},
   "source": [
    "# Resizing an Image for Optimal Stable Diffusion Processing\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This code resizes the previously loaded image to dimensions that work well with Stable Diffusion's image-to-image pipeline.\n",
    "\n",
    "## Technical Details\n",
    "\n",
    "- **Method**: Uses PIL's `resize()` function\n",
    "- **New Dimensions**: 768 pixels wide by 512 pixels high\n",
    "- **Aspect Ratio**: 3:2 (landscape orientation)\n",
    "- **Resolution**: Balances quality and processing speed\n",
    "\n",
    "## Why These Dimensions?\n",
    "\n",
    "- **Multiple of 64**: Stable Diffusion works optimally with dimensions that are multiples of 8, with 64 being ideal\n",
    "  - 768 = 12 × 64\n",
    "  - 512 = 8 × 64\n",
    "\n",
    "- **Memory Efficiency**: Keeps VRAM usage reasonable while maintaining good quality\n",
    "  - Total pixel count: 393,216 (768 × 512)\n",
    "  - Significantly less memory-intensive than higher resolutions\n",
    "\n",
    "- **Processing Speed**: Faster generation compared to larger dimensions\n",
    "  - Generation time typically increases exponentially with image size\n",
    "\n",
    "- **Quality Balance**: Provides sufficient detail for most image-to-image transformations\n",
    "\n",
    "Note that resizing may change the original aspect ratio if it differs from 3:2, potentially causing some distortion in the image. For images with significantly different proportions, cropping before resizing might better preserve important visual elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = init_image.resize((768, 512))\n",
    "\n",
    "print(f\"Image type: {type(init_image)}\")\n",
    "print(f\"Image dimensions: {init_image.size}\")\n",
    "print(f\"Image mode: {init_image.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be391c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(init_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d77a87",
   "metadata": {},
   "source": [
    "# Defining a Prompt for Stable Diffusion Image Transformation\n",
    "\n",
    "\n",
    "## Prompt Analysis\n",
    "\n",
    "This prompt combines several key elements to guide the image-to-image transformation:\n",
    "\n",
    "### Subject Matter\n",
    "- **\"a fantasy land\"**: Defines the core content\n",
    "  - Directs the model to generate fantastical, otherworldly landscapes\n",
    "  - Suggests magical or surreal elements beyond realistic scenery\n",
    "\n",
    "### Style Modifiers\n",
    "- **\"trending on artstation\"**: Implies modern digital art quality\n",
    "  - References a popular platform for professional digital artists\n",
    "  - Signals high-quality, detailed, and visually impressive results\n",
    "  - Typically produces vibrant colors and dramatic lighting\n",
    "\n",
    "- **\"by picasso\"**: Specifies an artistic influence\n",
    "  - Incorporates Pablo Picasso's distinctive cubist/abstract style\n",
    "  - Suggests geometric fragmentation and multiple perspectives\n",
    "  - Indicates non-realistic representation of forms and spaces\n",
    "\n",
    "## Expected Effect\n",
    "\n",
    "When applied to the previously loaded and resized image (768×512), this prompt will:\n",
    "\n",
    "1. Maintain the general composition and structure of the original image\n",
    "2. Transform it into a fantastical landscape with surreal elements\n",
    "3. Apply stylistic elements reminiscent of Picasso's cubist approach\n",
    "4. Enhance visual appeal with digital art aesthetics popular on ArtStation\n",
    "\n",
    "The combination creates an interesting style fusion between classical cubism and modern digital fantasy art trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a fantasy land, trending on artstation by picasso\"\n",
    "# prompt = \"show a peacock in this landscape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98eb6d8",
   "metadata": {},
   "source": [
    "# Generating the Image with Stable Diffusion\n",
    "\n",
    "This code executes the image-to-image generation using Stable Diffusion:\n",
    "\n",
    "### Input Preparation\n",
    "- `image_pil = init_image`: References the previously loaded and resized image\n",
    "- This step is technically redundant but clarifies that we're using a PIL Image object\n",
    "\n",
    "### CUDA Optimization\n",
    "- `torch.autocast(\"cuda\")`: Enables automatic mixed precision\n",
    "  - Improves performance by using lower precision where appropriate\n",
    "  - Reduces memory usage while maintaining quality\n",
    "  - Complements the fp16 model configuration set earlier\n",
    "\n",
    "### Generation Parameters\n",
    "- **Prompt**: The previously defined text \"a fantasy land, trending on artstation by picasso\"\n",
    "- **Strength**: `0.75` (75%)\n",
    "  - Controls how much to transform the original image\n",
    "  - 0.0 = no change, 1.0 = complete transformation\n",
    "  - 0.75 provides significant transformation while preserving original composition\n",
    "- **Guidance Scale**: `7.5`\n",
    "  - Determines how closely the image follows the text prompt\n",
    "  - Higher values (like 7.5) produce results that more strictly adhere to the prompt\n",
    "  - Lower values allow more creative variation\n",
    "\n",
    "### Error Handling\n",
    "- The try/except block catches potential errors during generation\n",
    "- Prints a success message if generation completes or an error message if it fails\n",
    "\n",
    "### Visualization\n",
    "- `display(output_image.images[0])`: Shows the generated image in the notebook\n",
    "- The output is a transformed version of the original with Picasso-inspired fantasy elements\n",
    "\n",
    "This approach creates a balance between preserving the original image's structure and applying the fantasy/cubist transformation specified in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As PIL Image (already have this)\n",
    "image_pil = init_image\n",
    "\n",
    "try:\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output_image = pipe(prompt=prompt, image=image_pil, strength=0.75, guidance_scale=7.5)\n",
    "    print(\"Success with PIL image!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with PIL image: {e}\")\n",
    "    \n",
    "display(output_image.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ade703",
   "metadata": {},
   "source": [
    "# Alternative Approach: Using NumPy Arrays for Image Input\n",
    "\n",
    "This code demonstrates an alternative method of providing the input image using NumPy arrays:\n",
    "\n",
    "### Image Conversion\n",
    "- `np.array(init_image)`: Converts the PIL Image to a NumPy array\n",
    "- `print(f\"NumPy array shape: {image_np.shape}\")`: Displays the array dimensions\n",
    "  - Expected output: `NumPy array shape: (512, 768, 3)` \n",
    "  - This corresponds to (height, width, RGB channels)\n",
    "\n",
    "### Stable Diffusion Processing\n",
    "- Uses identical parameters to the previous example:\n",
    "  - Same prompt: \"a fantasy land, trending on artstation by picasso\"\n",
    "  - Same strength: 0.75 (75% transformation)\n",
    "  - Same guidance scale: 7.5 (adherence to prompt)\n",
    "\n",
    "### Technical Benefits of NumPy Format\n",
    "- Flexibility for pre-processing (if needed):\n",
    "  - Direct pixel manipulation\n",
    "  - Channel adjustments\n",
    "  - Custom transformations\n",
    "- Compatibility with other libraries that work with NumPy arrays\n",
    "- Potential integration with ML preprocessing pipelines\n",
    "\n",
    "### Output Display\n",
    "- Shows the resulting transformed image in the notebook\n",
    "- Should produce results very similar to the PIL Image approach\n",
    "\n",
    "This demonstrates the pipeline's flexibility in accepting different input formats while maintaining the same generation parameters and artistic direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As NumPy array\n",
    "image_np = np.array(init_image)\n",
    "print(f\"NumPy array shape: {image_np.shape}\")\n",
    "\n",
    "try:\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output_image = pipe(prompt=prompt, image=image_np, strength=0.75, guidance_scale=7.5)\n",
    "    print(\"Success with NumPy array!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with NumPy array: {e}\")\n",
    "    \n",
    "display(output_image.images[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1952226",
   "metadata": {},
   "source": [
    "# Advanced Approach: Using PyTorch Tensors Directly\n",
    "\n",
    "This code demonstrates the most direct method for feeding images into Stable Diffusion using native PyTorch tensors:\n",
    "\n",
    "### Tensor Conversion Process\n",
    "- `torch.from_numpy(image_np)`: Converts NumPy array to PyTorch tensor\n",
    "- `.permute(2, 0, 1)`: Rearranges dimensions from:\n",
    "  - NumPy/PIL format: (Height, Width, Channels) \n",
    "  - To PyTorch format: (Channels, Height, Width)\n",
    "- `.float()`: Converts integer pixel values to floating point\n",
    "- `/ 255.0`: Normalizes pixel values from [0-255] to [0-1] range\n",
    "  - Required for proper model processing\n",
    "\n",
    "### Tensor Information\n",
    "- `print(f\"Tensor shape: {image_tensor.shape}\")`: Displays tensor dimensions\n",
    "  - Expected output: `Tensor shape: (3, 512, 768)`\n",
    "  - This corresponds to (RGB channels, height, width)\n",
    "\n",
    "### Generation Parameters\n",
    "- Same prompt and settings as previous examples:\n",
    "  - 75% transformation strength\n",
    "  - 7.5 guidance scale for prompt adherence\n",
    "\n",
    "### Technical Advantages\n",
    "- **Maximum Efficiency**: Eliminates conversion overhead within the pipeline\n",
    "- **GPU Memory Optimization**: Data already in format needed by model\n",
    "- **Integration Potential**: Perfect for workflows with other PyTorch models\n",
    "- **Fine Control**: Direct manipulation of tensor attributes if needed\n",
    "\n",
    "This approach represents the most \"native\" way to work with Stable Diffusion's pipeline, as the model internally works with tensors in exactly this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As PyTorch tensor\n",
    "image_tensor = torch.from_numpy(image_np).permute(2, 0, 1).float() / 255.0  # Convert to CHW format and normalize\n",
    "print(f\"Tensor shape: {image_tensor.shape}\")\n",
    "\n",
    "try:\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output_image = pipe(prompt=prompt, image=image_tensor, strength=0.75, guidance_scale=7.5)\n",
    "    print(\"Success with PyTorch tensor!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with PyTorch tensor: {e}\")\n",
    "    \n",
    "display(output_image.images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
